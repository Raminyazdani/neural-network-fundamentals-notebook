Ramin Yazdani | neural-network-fundamentals-notebook | main | feat(analysis): implement outlier generation for robustness analysis

Implement function to add outliers (label noise) to datasets for robustness testing.

Added add_outliers() function:
- Takes dataset (X, y) and number of outliers to create
- Randomly selects points and flips their labels
- Returns noisy dataset with mislabeled points
- Uses numpy.random for reproducibility

Outliers simulate real-world noisy data where some labels are incorrect due to:
- Measurement errors
- Human labeling mistakes
- Inherently ambiguous examples

This enables analysis of how robust different classifiers are to label noise,
which is a critical practical consideration.

Verified: Function correctly flips specified number of labels randomly.