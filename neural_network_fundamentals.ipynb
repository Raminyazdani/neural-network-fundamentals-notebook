{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Fundamentals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearly Separable Data Generation\n\nGenerate two clusters of points that can be separated by a linear boundary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n\n",
    "def generate_linearly_separable_data(n_samples=100, separation=2.0):\n",
    "    \"\"\"Generate two linearly separable clusters\"\"\"\n",
    "    np.random.seed(42)\n",
    "    cluster1 = np.random.randn(n_samples, 2) + [separation, separation]\n",
    "    cluster2 = np.random.randn(n_samples, 2) + [-separation, -separation]\n",
    "    X = np.vstack([cluster1, cluster2])\n",
    "    y = np.array([0] * n_samples + [1] * n_samples)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Dataset Generation\n\nGenerate the XOR dataset - a classic non-linearly separable problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xor_data():\n",
    "    \"\"\"Generate XOR dataset\"\"\"\n",
    "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "    y = np.array([0, 1, 1, 0])\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n\nVisualize the clusters and their labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n\n",
    "def visualize_data(X, y, title='Data Clusters'):\n",
    "    \"\"\"Visualize 2D data points\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X[y==0][:, 0], X[y==0][:, 1], c='blue', label='Class 0', alpha=0.6)\n",
    "    plt.scatter(X[y==1][:, 0], X[y==1][:, 1], c='red', label='Class 1', alpha=0.6)\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM Classification\n\nUsing scikit-learn to find a decision boundary for binary classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n\n",
    "# Generate and visualize linearly separable data\n",
    "X_linear, y_linear = generate_linearly_separable_data()\n",
    "visualize_data(X_linear, y_linear, 'Linearly Separable Data')\n\n",
    "# Train Linear SVM\n",
    "svm_linear = LinearSVC(random_state=42, max_iter=10000)\n",
    "svm_linear.fit(X_linear, y_linear)\n",
    "print(f'Linear SVM accuracy: {svm_linear.score(X_linear, y_linear):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Boundary Visualization\n\nVisualize the decision boundary learned by the classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(X, y, model, title='Decision Boundary'):\n",
    "    \"\"\"Plot decision boundary for 2D classification\"\"\"\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdYlBu)\n",
    "    plt.scatter(X[y==0][:, 0], X[y==0][:, 1], c='blue', label='Class 0', edgecolors='k')\n",
    "    plt.scatter(X[y==1][:, 0], X[y==1][:, 1], c='red', label='Class 1', edgecolors='k')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decision boundary for linear data\n",
    "plot_decision_boundary(X_linear, y_linear, svm_linear, 'Linear SVM on Linearly Separable Data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try Linear SVM on XOR dataset\n",
    "X_xor, y_xor = generate_xor_data()\n",
    "visualize_data(X_xor, y_xor, 'XOR Dataset')\n\n",
    "svm_xor_linear = LinearSVC(random_state=42, max_iter=10000)\n",
    "svm_xor_linear.fit(X_xor, y_xor)\n",
    "print(f'Linear SVM on XOR accuracy: {svm_xor_linear.score(X_xor, y_xor):.4f}')\n",
    "plot_decision_boundary(X_xor, y_xor, svm_xor_linear, 'Linear SVM on XOR (Poor Performance)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Optimization\n\nOptimize the model using different kernels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n\n",
    "# Try RBF kernel on XOR with tuning\n",
    "svm_xor_rbf = SVC(kernel='rbf', gamma='scale', C=1.0, random_state=42)\n",
    "svm_xor_rbf.fit(X_xor, y_xor)\n",
    "print(f'RBF SVM on XOR accuracy: {svm_xor_rbf.score(X_xor, y_xor):.4f}')\n",
    "plot_decision_boundary(X_xor, y_xor, svm_xor_rbf, 'RBF SVM on XOR (Perfect Separation)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations: Linear vs Non-Linear Classification\n\n",
    "Linear models work well for linearly separable data but fail on non-linear problems like XOR.\n",
    "Non-linear kernels (like RBF) can handle complex decision boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact of Outliers on Decision Boundary\n\nAnalyze how outliers affect the decision boundary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create outliers by flipping labels\n",
    "def add_outliers(X, y, n_outliers=5):\n",
    "    \"\"\"Add outliers by randomly flipping labels\"\"\"\n",
    "    X_outlier = X.copy()\n",
    "    y_outlier = y.copy()\n",
    "    outlier_indices = np.random.choice(len(y), n_outliers, replace=False)\n",
    "    y_outlier[outlier_indices] = 1 - y_outlier[outlier_indices]\n",
    "    return X_outlier, y_outlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add outliers and retrain\n",
    "np.random.seed(42)\n",
    "X_outlier, y_outlier = add_outliers(X_linear, y_linear, n_outliers=10)\n",
    "visualize_data(X_outlier, y_outlier, 'Data with Outliers')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}